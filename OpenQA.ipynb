{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# ######################## PART 3: YOUR WORK HERE ########################\n",
    "\"\"\"\n",
    "3. Open-domain question answering (45 pts)\n",
    "In this part, you will need to implement a model similar to Dense Passage Retrieval for\n",
    "Open-Domain Question Answering by Karpukhin et al (2020). Before starting, please go over\n",
    "the paper, and optionally read this blog post section on open-domain QA and skim over the\n",
    "DPR code repository.\n",
    "For the assignment, you are given CSV files in data/qa that correspond to the training Q&A\n",
    "pairs, validation pairs, test questions, and answers.csv that contains all the answers. The data is\n",
    "taken from a Q&A forum about cooking, and at the end of this section you will have built a\n",
    "model that can automatically retrieve (i.e. search) relevant answers for any question about\n",
    "cooking.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_models_and_tokenizer(q_name, a_name, t_name, device='cuda'):\n",
    "    \"\"\"\n",
    "    In part 1, you used an object-oriented approach to load a custom distilbert model. This time, you\n",
    "    need to load two models (one for encoding the questions, another for encoding the candidate\n",
    "    answers, and they have separate weights but same embedding dimensions). You will use a\n",
    "    simpler approach this time; simply build functions that load and return the models, perform\n",
    "    slicing, and generate tokens, all separate from OOP.\n",
    "    load_models_and_tokenizer\n",
    "    For this, we will be testing with the string 'google/electra-small-discriminator' but\n",
    "    your function should work with other names as well. You do not review ELECTRA, other than\n",
    "    knowing that this is a pretrained model that performs well but is much smaller than DistilBERT\n",
    "    and has smaller embedding size. You should be comfortable loading other models from\n",
    "    Huggingface, as hundreds of them exist.\n",
    "    ParameterTypeDescription\n",
    "    q_namestrName of the model that will be passed to transformers to\n",
    "    automatically load the pre-trained version, and used for encoding\n",
    "    questions. It must be something that can be found on\n",
    "    Huggingface Hub, just like you’ve previously done.\n",
    "    a_namestrName of the model encoding the answers.\n",
    "    t_namestrName of the tokenizer, which will be passed to transformers to\n",
    "    automatically load the corresponding pre-trained tokenizer.\n",
    "    devicestr“cuda” or “cuda”, the models will be loaded here.\n",
    "    ReturnsType\n",
    "    Descriptionq_enctransformers\n",
    "    ModelThe question encoder model, which is a huggingface\n",
    "    transformer. This corresponds to q_name\n",
    "    a_enctransformers\n",
    "    ModelThe candidate answers the encoder model, which is a\n",
    "    huggingface transformer. This corresponds to a_name\n",
    "    tokenizertransformers\n",
    "    tokenizerThe tokenizer that will be used for each of the models. For\n",
    "    simplicity, it will be shared, but in theory you could have\n",
    "    separate tokenizers if you use different models for\n",
    "    encoding questions and answers, but this is rare in\n",
    "    practice.\n",
    "    :param q_name:\n",
    "    :param a_name:\n",
    "    :param t_name:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    q_enc = transformers.ElectraModel.from_pretrained(q_name).to(device)\n",
    "    a_enc = transformers.ElectraModel.from_pretrained(a_name).to(device)\n",
    "    tokenizer = transformers.ElectraTokenizer.from_pretrained(t_name)\n",
    "    return q_enc, a_enc, tokenizer\n",
    "\n",
    "\n",
    "def tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers, max_length=64):\n",
    "    \"\"\"\n",
    "    tokenize_qa_batch\n",
    "    Tokenize question titles/bodies and answers into two input batches. The following conditions\n",
    "    apply:\n",
    "    ● The input_ids returned should be Pytorch tensors\n",
    "    ● The content should be truncated using the default method if it exceeds max_length\n",
    "    ● You should only pad everything to the longest sequence in a batch\n",
    "    ● The title and body should be tokenized together as a pair, separated with a [SEP] token.\n",
    "    ● The answers should be tokenized separately\n",
    "    ● q_titles,q_bodies, answers are all lists of the same length\n",
    "    ParameterTypeDescription\n",
    "    tokenizertransformers\n",
    "    tokenizerA huggingface tokenizer returned by your previous\n",
    "    function.\n",
    "    q_titleslist of strThe list of titles of the questions\n",
    "    q_bodieslist of strThe list of questions bodies (actual content)\n",
    "    answerslist of strThe contents of the corresponding answers\n",
    "    max_lengthintThe maximum length of the tokens, after which it is\n",
    "    truncated\n",
    "    ReturnsTypeDescription\n",
    "    q_batchBatchEncodingA \"BatchEncoding\" (inherited from a dict) containing\n",
    "    the question titles and bodies, which can be used as\n",
    "    the input of a transformer model (which means the\n",
    "    input IDs are PyTorch tensors)\n",
    "    a_batch\n",
    "    BatchEncoding\n",
    "    A \"BatchEncoding\" (inherited from a dict) containing\n",
    "    the answer bodies, which can be used as the input of a\n",
    "    transformer model.\n",
    "    :param tokenizer:\n",
    "    :param q_titles:\n",
    "    :param q_bodies:\n",
    "    :param answers:\n",
    "    :param max_length:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below.\n",
    "    q_batch = tokenizer(\n",
    "        q_titles,\n",
    "        q_bodies,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    a_batch = tokenizer(\n",
    "        answers,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return q_batch, a_batch\n",
    "\n",
    "\n",
    "def get_class_output(model, batch):\n",
    "    \"\"\"\n",
    "    Since this is similar to a previous question, it is left ungraded.\n",
    "    ReturnsDescription\n",
    "    BaseModelOutputThe output representation of the class token (for example [CLS])\n",
    "    after encoding the tokenized text through your model.\n",
    "    :param model:\n",
    "    :param batch:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Since this is similar to a previous question, it is left ungraded\n",
    "    # TODO: your work below.\n",
    "    return model(**batch, return_dict=True).last_hidden_state[:, 0, :]\n",
    "\n",
    "\n",
    "def inbatch_negative_sampling(Q: Tensor, P: Tensor, device: str = 'cuda') -> Tensor:\n",
    "    \"\"\"\n",
    "    3.3 Batch: Implement in-batch negative sampling (7 pts)\n",
    "    The in-batch negative sampling method uses the answers from other questions in the same\n",
    "    batch as the negative examples (because they are unrelated as they are randomly taken from\n",
    "    the training set). Please read the relevant section in the paper and implement it accordingly.\n",
    "    inbatch_negative_sampling\n",
    "    This function should take the tensors of questions Q and passages P, and use the in-batch\n",
    "    negatives (as described in the paper) to compute a similarity matrix evaluated on each of the N\n",
    "    questions with the M passages. Although we call it “sampling”, you are computing it over all\n",
    "    passages in a batch rather than taking a subsample of the batch. You can find a way to do both\n",
    "    the “negative sampling” and computing similarity at the same time; you can read the paper to\n",
    "    find out how to do that.\n",
    "    ParameterTypeDescription\n",
    "    QTensor[N, E]The output representation of N question titles+bodies\n",
    "    PTensor[M, E]The output representation of M answers (aka passages)\n",
    "    devicestr“cuda” or “cuda”, the models will be loaded here.\n",
    "    ReturnsDescription\n",
    "    Tensor[N, M]The matrix of similarity score that results from in-batch negative\n",
    "    sampling.\n",
    "    :param Q:\n",
    "    :param P:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    Q = Q.to(device)\n",
    "    P = P.to(device)\n",
    "    return torch.matmul(Q, P.T)\n",
    "\n",
    "\n",
    "def contrastive_loss_criterion(S: Tensor, labels: Tensor = None, device: str = 'cuda'):\n",
    "    \"\"\"\n",
    "    Contrastive loss is different from the loss functions we have previously been exposed to. You\n",
    "    have previously seen loss functions for classification and for text generation, but retrieval\n",
    "    requires something different. You will need to implement the loss function described in the DPR\n",
    "    paper (please read the equations carefully), and the official source code shows how to\n",
    "    implement it in Pytorch.\n",
    "    contrastive_loss_criterion\n",
    "    ParameterTypeDescription\n",
    "    STensor[N, M]The matrix of similarity score that results from in-batch\n",
    "    negative sampling.\n",
    "    labelsTensor[N]The optional label indices between 0-M. For example [0, 2,\n",
    "    M,..., 1] respectively indicate that the\n",
    "    ● Passage #0 is the answer for Question #0\n",
    "    ● Passage #2 is the answer for Question #1\n",
    "    ● Passage #M is the answer for Question #2\n",
    "    ● …\n",
    "    ● Passage #1 is the answer for Question #N\n",
    "    If labels=None, simply return a tensor with values such at\n",
    "    Passage #0 corresponds to Question #0, P1 with Q1, etc.\n",
    "    devicestr“cuda” or “cuda”, the models will be loaded here.\n",
    "    ReturnsDescription\n",
    "    Tensor(1)A scalar tensor on which you can call backward to initiate the backprop\n",
    "    process. The value represents the loss, which means a lower value\n",
    "    means the model has a low error when matching the questions with the\n",
    "    passages.\n",
    "    :param S:\n",
    "    :param labels:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    if labels is None:\n",
    "        labels = torch.arange(S.size(0), device=device)\n",
    "    return torch.nn.functional.cross_entropy(S, labels)\n",
    "\n",
    "\n",
    "def get_topk_indices(Q, P, k: int = None):\n",
    "    \"\"\"\n",
    "    get_topk_indices\n",
    "    Compute the dot-product similarity score (without normalizing or cosine scaling) and return the\n",
    "    indices and scores for the top-k candidate answers for each question in Q.\n",
    "    ParameterTypeDescription\n",
    "    QTensor[N, E]The output class representation for question title+body\n",
    "    PTensor[M, E]The output class representation for answer (aka\n",
    "    passage)\n",
    "    kintThe number of indices to return based on the similarity.When k=None, simply return everything in the sorted\n",
    "    order.\n",
    "    ReturnsTypeDescription\n",
    "    indicesTensor[N, k] of intThe sorted indices of the most similar answers for each\n",
    "    of N questions (from largest to smallest magnitude)\n",
    "    scoresTensor[N, k] of intThe dot-product similarity score for the corresponding\n",
    "    indices\n",
    "    :param Q:\n",
    "    :param P:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    scores = torch.matmul(Q, P.T)\n",
    "    indices = torch.argsort(scores, dim=1, descending=True)\n",
    "    if k is not None:\n",
    "        indices = indices[:, :k]\n",
    "        scores = scores.gather(1, indices)\n",
    "    return indices, scores\n",
    "\n",
    "\n",
    "def select_by_indices(indices: Tensor, passages: 'list[str]') -> 'list[str]':\n",
    "    \"\"\"\n",
    "        select_by_indices\n",
    "    ParameterTypeDescription\n",
    "    indicesTensor[N, k] of intThe sorted indices of the most similar answers for each\n",
    "    of N questions (from largest to smallest magnitude)\n",
    "    passageslist of strA list of answers in the original textual format (before\n",
    "    tokenization). The length should be greater than the\n",
    "    largest index in indices (i.e. M).\n",
    "    Returns\n",
    "    Description\n",
    "    list of list of str\n",
    "    ●\n",
    "    ●\n",
    "    The outer lists correspond to answers for the the N questions\n",
    "    The inner lists contain the k sorted answers in original text format\n",
    "    :param indices:\n",
    "    :param passages:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    return [[passages[i] for i in idx] for idx in indices]\n",
    "\n",
    "\n",
    "def embed_passages(passages: 'list[str]', model, tokenizer, device='cuda', max_length=512):\n",
    "    \"\"\"\n",
    "    First, set the model into the evaluation mode and disable gradients, then embed a list of\n",
    "    passages.\n",
    "    ParameterTypeDescription\n",
    "    passageslist of strA list of answers in the original textual format (before\n",
    "    tokenization). The length should be greater than the largest index\n",
    "    in indices (i.e. M).\n",
    "    modelThe Huggingface transformer model used to encode the text\n",
    "    tokenizerThe Huggingface tokenizer used to encode the passages\n",
    "    Returns\n",
    "    Description\n",
    "    Tensor[M, E]\n",
    "    The output class representation for answer (aka passage)\n",
    "    :param passages:\n",
    "    :param model:\n",
    "    :param tokenizer:\n",
    "    :param device:\n",
    "    :param max_length:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_passages = tokenizer(passages, padding=True, truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        outputs = model(**encoded_passages, return_dict=True)\n",
    "        passage_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return passage_embeddings\n",
    "\n",
    "\n",
    "def embed_questions(titles, bodies, model, tokenizer, device='cuda', max_length=512):\n",
    "    \"\"\"\n",
    "    First, set the model into the evaluation mode and disable gradients. Then, embed titles and\n",
    "    bodies at the same time using the question model (review BERT to see how this is possible).\n",
    "    ParameterTypeDescription\n",
    "    titleslist of strA list of titles in the original textual format (before tokenization).\n",
    "    The length should be greater than the largest index in indices (i.e.\n",
    "    M).\n",
    "    bodieslist of strThe bodies corresponding to each title.\n",
    "    modelThe Huggingface transformer model used to encode the text\n",
    "    tokenizerThe Huggingface tokenizer used to encode the passages\n",
    "    ReturnsDescription\n",
    "    Tensor[N, E]The output class representation for questions (titles with bodies)\n",
    "    :param titles:\n",
    "    :param bodies:\n",
    "    :param model:\n",
    "    :param tokenizer:\n",
    "    :param device:\n",
    "    :param max_length:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Combine titles and bodies with the [SEP] token\n",
    "        combined_texts = [\"[CLS] \" + title + \" [SEP] \" + body for title, body in zip(titles, bodies)]\n",
    "        encoded_questions = tokenizer(combined_texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length).to(device)\n",
    "        outputs = model(**encoded_questions, return_dict=True)\n",
    "        question_embeddings = outputs.last_hidden_state[:, 0, :]  # Use the pooled output for question embeddings\n",
    "    return question_embeddings\n",
    "\n",
    "\n",
    "def recall_at_k(retrieved_indices: 'list[list[int]]', true_indices: 'list[int]', k: int):\n",
    "    \"\"\"\n",
    "    You can review the recall score here. Note that since we are returning k elements, we want to\n",
    "    know if the correct answer is in one of the k elements, hence we are calling this the “recall”\n",
    "    score, though it might feel different from how we use recall for binary classification.\n",
    "    ParameterTypeDescription\n",
    "    retrieved_indiceslist of list of\n",
    "    intouter list: The retrieved results for each of N questions\n",
    "    inner list: The k indices ranked in order of estimated\n",
    "    relevance\n",
    "    true_indiceslist of intThe correct index for each of N questions, same length as\n",
    "    retrieved_indices’s outer list\n",
    "    kintThe number of inner items in retrieved_indices to consider;\n",
    "    k must be smaller than the length of the inner lists\n",
    "    ReturnsDescriptionfloat\n",
    "    A single score representing the recall at k score\n",
    "    :param retrieved_indices:\n",
    "    :param true_indices:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    return sum([1 if true in retrieved[:k] else 0 for retrieved, true in zip(retrieved_indices, true_indices)]) / len(retrieved_indices)\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(retrieved_indices: 'list[list[int]]', true_indices: 'list[int]'):\n",
    "    \"\"\"\n",
    "    Please refer to recall_at_k, except you are now returning the Mean Reciprocal Rank, and\n",
    "    there’s no parameter k. You can read more about this on Wikipedia. The mean reciprocal rank is a statistic measure\n",
    "    for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability\n",
    "    of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first\n",
    "    correct answer: 1 for first place, 1⁄2 for second place, 1⁄3 for third place and so on. The mean reciprocal rank is\n",
    "    the average of the reciprocal ranks of results for a sample of queries Q\n",
    "    :param retrieved_indices:\n",
    "    :param true_indices:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: your work below\n",
    "    assert len(retrieved_indices) == len(true_indices), \"Length of retrieved_indices and true_indices must be equal.\"\n",
    "\n",
    "    reciprocal_ranks = []\n",
    "    for retrieved, true in zip(retrieved_indices, true_indices):\n",
    "        if true in retrieved:\n",
    "            rank = retrieved.index(true) + 1\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)\n",
    "\n",
    "    return sum(reciprocal_ranks) / len(reciprocal_ranks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Recall@10: 0.2970, MRR: 0.0935\n",
      "Epoch 1 - Recall@10: 0.2772, MRR: 0.0923\n",
      "Epoch 2 - Recall@10: 0.4455, MRR: 0.2298\n",
      "Epoch 2 - Recall@10: 0.4158, MRR: 0.1667\n",
      "Epoch 3 - Recall@10: 0.6535, MRR: 0.4089\n",
      "Epoch 3 - Recall@10: 0.6733, MRR: 0.3531\n",
      "Epoch 4 - Recall@10: 0.7822, MRR: 0.5342\n",
      "Epoch 4 - Recall@10: 0.6733, MRR: 0.4365\n",
      "Epoch 5 - Recall@10: 0.8812, MRR: 0.6166\n",
      "Epoch 5 - Recall@10: 0.6832, MRR: 0.4532\n",
      "Epoch 6 - Recall@10: 0.9406, MRR: 0.7064\n",
      "Epoch 6 - Recall@10: 0.7129, MRR: 0.4764\n",
      "Epoch 7 - Recall@10: 0.9604, MRR: 0.7909\n",
      "Epoch 7 - Recall@10: 0.7228, MRR: 0.4599\n",
      "Epoch 8 - Recall@10: 0.9604, MRR: 0.8054\n",
      "Epoch 8 - Recall@10: 0.6832, MRR: 0.4181\n",
      "Epoch 9 - Recall@10: 0.9703, MRR: 0.8408\n",
      "Epoch 9 - Recall@10: 0.6931, MRR: 0.4541\n",
      "Epoch 10 - Recall@10: 1.0000, MRR: 0.9178\n",
      "Epoch 10 - Recall@10: 0.7129, MRR: 0.4549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score  # Make sure sklearn is installed\n",
    "\n",
    "random.seed(2022)\n",
    "torch.manual_seed(2022)\n",
    "\n",
    "# Parameters (you can change them)\n",
    "sample_size = 2500  # Change this if you want to take a subset of data for testing\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "num_words = 50000\n",
    "\n",
    "# If you use GPUs, use the code below:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ###################### PART 3: TEST CODE ######################\n",
    "# Preliminary\n",
    "bsize = 8\n",
    "qa_data = dict(\n",
    "    train=pd.read_csv('data/qa/train.csv'),\n",
    "    valid=pd.read_csv('data/qa/validation.csv'),\n",
    "    answers=pd.read_csv('data/qa/answers.csv'),\n",
    ")\n",
    "\n",
    "# Loading huggingface models and tokenizers\n",
    "name = 'google/electra-small-discriminator'\n",
    "q_enc, a_enc, tokenizer = load_models_and_tokenizer(q_name=name, a_name=name, t_name=name)\n",
    "q_enc = q_enc.to(device)\n",
    "a_enc = a_enc.to(device)\n",
    "\n",
    "# Get optimizer\n",
    "optimizer = torch.optim.Adam(list(q_enc.parameters()) + list(a_enc.parameters()), lr=1e-5)\n",
    "\n",
    "# Report your results on open-domain question answering similar to part 1. Train your model for 10 epochs, and compute the evaluation scores at the end of an epoch. Please read all subsections before starting your report.\n",
    "train_recall = []\n",
    "valid_recall = []\n",
    "train_mrr = []\n",
    "valid_mrr = []\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(qa_data['train']), batch_size):\n",
    "        # Get batch\n",
    "        q_titles = qa_data['train'].loc[i : i + batch_size, 'QuestionTitle'].tolist()\n",
    "        q_bodies = qa_data['train'].loc[i : i + batch_size, 'QuestionBody'].tolist()\n",
    "        answers = qa_data['train'].loc[i : i + batch_size, 'Answer'].tolist()\n",
    "        # Tokenize batch and get class output\n",
    "        q_batch, a_batch = tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers)\n",
    "        q_batch = q_batch.to(device)\n",
    "        a_batch = a_batch.to(device)\n",
    "\n",
    "        q_out = get_class_output(q_enc, q_batch)\n",
    "        a_out = get_class_output(a_enc, a_batch)\n",
    "\n",
    "        # Compute similarity matrix\n",
    "        S = inbatch_negative_sampling(q_out, a_out)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = contrastive_loss_criterion(S)\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "    # Compute evaluation scores on entire train and validation set\n",
    "    q_titles = qa_data['train'].loc[:100, 'QuestionTitle'].tolist()\n",
    "    q_bodies = qa_data['train'].loc[:100, 'QuestionBody'].tolist()\n",
    "    answers = qa_data['train'].loc[:100, 'Answer'].tolist()\n",
    "    # Tokenize batch and get class output\n",
    "    q_batch, a_batch = tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers)\n",
    "    q_batch = q_batch.to(device)\n",
    "    a_batch = a_batch.to(device)\n",
    "    q_out = get_class_output(q_enc, q_batch)\n",
    "    a_out = get_class_output(a_enc, a_batch)\n",
    "    # Get top-k indices\n",
    "    indices, scores = get_topk_indices(q_out, a_out, k=10)\n",
    "    indices = indices.cpu().tolist()\n",
    "    # Select by indices\n",
    "    selected = select_by_indices(indices, answers)\n",
    "    # Compute recall at k\n",
    "    recall = recall_at_k(indices, list(range(len(answers))), k=10)\n",
    "    # Compute mean reciprocal rank\n",
    "    mrr = mean_reciprocal_rank(indices, list(range(len(answers))))\n",
    "    print(f\"Epoch {epoch + 1} - Recall@10: {recall:.4f}, MRR: {mrr:.4f}\")\n",
    "    train_recall.append(recall)\n",
    "    train_mrr.append(mrr)\n",
    "\n",
    "    # Validation\n",
    "    q_titles = qa_data['valid'].loc[:100, 'QuestionTitle'].tolist()\n",
    "    q_bodies = qa_data['valid'].loc[:100, 'QuestionBody'].tolist()\n",
    "    answers = qa_data['valid'].loc[:100, 'Answer'].tolist()\n",
    "    # Tokenize batch and get class output\n",
    "    q_batch, a_batch = tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers)\n",
    "    q_batch = q_batch.to(device)\n",
    "    a_batch = a_batch.to(device)\n",
    "    q_out = get_class_output(q_enc, q_batch)\n",
    "    a_out = get_class_output(a_enc, a_batch)\n",
    "    # Get top-k indices\n",
    "    indices, scores = get_topk_indices(q_out, a_out, k=10)\n",
    "    indices = indices.cpu().tolist()\n",
    "    # Select by indices\n",
    "    selected = select_by_indices(indices, answers)\n",
    "    # Compute recall at k\n",
    "    recall = recall_at_k(indices, list(range(len(answers))), k=10)\n",
    "    # Compute mean reciprocal rank\n",
    "    mrr = mean_reciprocal_rank(indices, list(range(len(answers))))\n",
    "    print(f\"Epoch {epoch + 1} - Recall@10: {recall:.4f}, MRR: {mrr:.4f}\")\n",
    "    valid_recall.append(recall)\n",
    "    valid_mrr.append(mrr)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_recall, label='Train Recall@10')\n",
    "plt.plot(valid_recall, label='Valid Recall@10')\n",
    "plt.plot(train_mrr, label='Train MRR')\n",
    "plt.plot(valid_mrr, label='Valid MRR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Training and Validation Scores')\n",
    "plt.legend()\n",
    "plt.savefig('qa_scores.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Title: Office (Loose Leaf) Tea Solution\n",
      "Question Body: I am looking for a good system to make loose leaf tea at my workplace. The main requirements are that the tea tastes good and it is easy to clean in the toilet sink without much equipment. Bonus points if it's microwaveable, since I find that slightly more practical than an electric kettle.\n",
      "\n",
      "\n",
      "I have considered:\n",
      "\n",
      "\n",
      "* cup with a ceramic or glass strainer. Doubts: is the mesh fine enough, or would it let the smaller leaves through?\n",
      "* steel strainers. Doubts: do they affect the water taste? Can they be closed tightly, or would they let the smaller leaves through? Is the steel mesh microwavreable?\n",
      "* cotton strainers. Doubts: do they dry in a reasonable time? Do they get dark and dirty after a few uses?\n",
      "* fillable disposable tea bags. Doubts: are they viable for a single person? They look quite expensive\n",
      "* French press, ingenuitea, or other similar contraptions. Doubts: they don't look easy to clean at all. Are they microwaveable?\n",
      "\n",
      "\n",
      "What is your experience? Do you recommend (or suggest to avoid) one of these methods, or a new one?\n",
      "\n",
      "\n",
      "Related questions: [What's the best option for water for tea in the office?](https://cooking.stackexchange.com/questions/18735/whats-the-best-option-for-water-for-tea-in-the-office), [Best Office Coffee Solution](https://cooking.stackexchange.com/questions/3791/best-office-coffee-solution)\n",
      "\n",
      "\n",
      "\n",
      "True Answer: I've been drinking loose-leaf tea at work for many years now, and have gone through most of these.\n",
      "\n",
      "\n",
      "* cup with a ceramic or glass strainer.\n",
      "\n",
      "\n",
      "I've tried both the ceramic type with holes and the glass type with slots. The mesh is never fine enough for me. In addition the holes or slots invariably get packed with leaves and are a pain to clean.\n",
      "\n",
      "\n",
      "![ceramic strainer](https://i.stack.imgur.com/lpjHzs.jpg) ![glass strainer](https://i.stack.imgur.com/9f2pTs.jpg)\n",
      "\n",
      "\n",
      "* steel strainers.\n",
      "\n",
      "\n",
      "If you mean the tea-ball type, I can't comment. But a steel mesh strainer is my absolute favorite. I've been using the same one (pictured below) for years now and have never noticed any off flavors. Easy to clean: just dump out the leaves and give a good rinse, picking or sponging out the occasional stuck leaf.\n",
      "\n",
      "\n",
      "Not microwaveable, but you don't want to microwave the leaves, anyway. Microwave the cup with water in it (put a stirrer in to avoid superheating the water. Yes, it can happen, and has happened to me), then put the strainer in when it's the right temperature.\n",
      "\n",
      "\n",
      "![steel strainer](https://i.stack.imgur.com/3YuNes.jpg)\n",
      "\n",
      "\n",
      "* cotton strainers.\n",
      "\n",
      "\n",
      "I have never used one, so I can't comment authoritatively, but it seems like at the least they'd be harder to clean.\n",
      "\n",
      "\n",
      "* fillable disposable tea bags.\n",
      "\n",
      "\n",
      "I hate disposable anything. I tried the type of bag pictured below and they were a pain. They tend to wick tea out of the cup and onto your table.\n",
      "\n",
      "\n",
      "![tea bags](https://i.stack.imgur.com/0xKqws.jpg)\n",
      "\n",
      "\n",
      "As for the other gizmos, I think for tea, simpler is better. The above are the only methods I've used, and I find the mesh basket is far and away the most convenient and best solution.\n",
      "\n",
      "\n",
      "\n",
      "Predicted Answer: ['Normal double-acting baking powder makes CO2 (thus giving a rising effect) in two ways: when it gets wet, and when it is heated.\\n\\n\\nBaking soda only makes CO2 when it gets wet.\\n\\n\\n[From Wikipedia](http://en.wikipedia.org/wiki/Baking_powder):\\n\\n\\n\\n> \\n> The acid in a baking powder can be\\n>  either fast-acting or slow-acting.[6]\\n>  A fast-acting acid reacts in a wet\\n>  mixture with baking soda at room\\n>  temperature, and a slow-acting acid\\n>  will not react until heated in an\\n>  oven. Baking powders that contain both\\n>  fast- and slow-acting acids are double\\n>  acting; those that contain only one\\n>  acid are single acting. By providing a\\n>  second rise in the oven, double-acting\\n>  baking powders increase the\\n>  reliability of baked goods by\\n>  rendering the time elapsed between\\n>  mixing and baking less critical, and\\n>  this is the type most widely available\\n>  to consumers today. \\n> \\n> \\n> \\n\\n\\n', 'I place the bacon in a cold oven and then turn the oven on to 400F. It takes about 15-20 minutes to get slightly crisp bacon. \\n\\n\\n', 'Baking soda is pure sodium bicarbonate, while baking powder includes an acidifying agent (cream of tartar) and a drying agent (starch).\\n\\n\\nYou can substitute baking soda for baking powder if you already have an acidifying agent in a recipe (like buttermilk).\\n\\n\\n<http://chemistry.about.com/cs/foodchemistry/f/blbaking.htm>\\n\\n\\n']\n",
      "\n",
      "Question Title: My hotpot has a stand attached to it\n",
      "Question Body: So my dad bought a hot pot. I know what you cook in a hot pot. It says in the bottom \"Hot Pot.\" But the bottom isn't what I expected. Normally, a hotpot is in a bowl shape. But this one has somewhat a stand. It's like a small inverted bowl attached to the bottom and it keeps the hotpot still. It's hollow. Is this normal? How do I use this hotpot? Do I just place the hotpot with it's stand on top of a stove?\n",
      "\n",
      "\n",
      "\n",
      "True Answer: You say you know what to cook in a Hot Pot and confirm that this product is identified on the body as a 'Hot Pot', but I think the issue may be that 'Hot Pot' means different things in different cuisines.\n",
      "Where I come from a Hot pot is a lamb, potato and onion dish which is slow cooked in an oven. In East Asia it is a soup that simmers on the table while you cook morsels of ingredients in the broth. In India/South Asia, it is a vessel designed to keep cooked food warm until it is needed some hours later.\n",
      "\n",
      "\n",
      "I suspect you were looking for a vessel suitable for the East Asian Hot Pot but what you have is an Indian Hot Pot.\n",
      "\n",
      "\n",
      "This [short advertising video](https://youtu.be/3nPU-nIttdU) includes a model called a ‘dome hot pot’ which looks very similar to the one you have., and the video description call these ‘insulated casseroles’. \n",
      "\n",
      "\n",
      "I can’t find explicit product details for an insulated hot pot with a ‘foot’ design, but insulated or double walled hot pots are for keeping food warm, **not** for cooking it. As an example here’s a Q&A for a flat based version on amazon.co.uk[![screenshot showing amazon customer explaining how the insulation in his hot pot expanded and split the pot when he put it on the stove](https://i.stack.imgur.com/Gktuw.png)](https://i.stack.imgur.com/Gktuw.png)\n",
      "\n",
      "\n",
      "Also from [Attila brand hot pot on Amazon](https://www.amazon.co.uk/SQ-Professional-Thermal-Insulated-Stainless/dp/B01M71F5EG):\n",
      "\n",
      "\n",
      "\n",
      "> \n",
      "> Do not place the Attila Hot Pot on hot surfaces or near open fire\n",
      "> \n",
      "> \n",
      "> \n",
      "\n",
      "\n",
      "So, if I am correct and you have an insulated casserole, I would recommend you only use it to keep food warm, and do not place it on a stove. \n",
      "\n",
      "\n",
      "Indicators that it is an insulated casserole/hot pot would be:\n",
      "- Indian origin\n",
      "- lock/clip lid to keep food tightly sealed\n",
      "- thick side walls and lid indicating two layers of metal with vacuum or insulation between. \n",
      "\n",
      "\n",
      "\n",
      "Predicted Answer: ['I place the bacon in a cold oven and then turn the oven on to 400F. It takes about 15-20 minutes to get slightly crisp bacon. \\n\\n\\n', 'Normal double-acting baking powder makes CO2 (thus giving a rising effect) in two ways: when it gets wet, and when it is heated.\\n\\n\\nBaking soda only makes CO2 when it gets wet.\\n\\n\\n[From Wikipedia](http://en.wikipedia.org/wiki/Baking_powder):\\n\\n\\n\\n> \\n> The acid in a baking powder can be\\n>  either fast-acting or slow-acting.[6]\\n>  A fast-acting acid reacts in a wet\\n>  mixture with baking soda at room\\n>  temperature, and a slow-acting acid\\n>  will not react until heated in an\\n>  oven. Baking powders that contain both\\n>  fast- and slow-acting acids are double\\n>  acting; those that contain only one\\n>  acid are single acting. By providing a\\n>  second rise in the oven, double-acting\\n>  baking powders increase the\\n>  reliability of baked goods by\\n>  rendering the time elapsed between\\n>  mixing and baking less critical, and\\n>  this is the type most widely available\\n>  to consumers today. \\n> \\n> \\n> \\n\\n\\n', 'Baking soda is pure sodium bicarbonate, while baking powder includes an acidifying agent (cream of tartar) and a drying agent (starch).\\n\\n\\nYou can substitute baking soda for baking powder if you already have an acidifying agent in a recipe (like buttermilk).\\n\\n\\n<http://chemistry.about.com/cs/foodchemistry/f/blbaking.htm>\\n\\n\\n']\n",
      "\n",
      "Question Title: My salmon burgers are bland\n",
      "Question Body: I just tried to fry a salmon fillet and eat it as a I would a hamburger patty: with bread, cucumber and tomato. No matter my seasoning, I keep finding the taste bland.\n",
      "\n",
      "\n",
      "What could I do to enhance the taste when it comes to spices and other ingredients?\n",
      "\n",
      "\n",
      "\n",
      "True Answer: I would squeeze a lemon over the fish when it was done, and then make a sauce for it. You can do like an Aioli or flavored mayonnaise, using ingredients such as capers, dill, lemon etc.. whatever you would normally like on regular cooked salmon. \n",
      "\n",
      "\n",
      "Also, you will find a difference in taste between a farm raised and wild-caught salmon. Wild caught salmon have redder flesh (although some places have started dyeing farmed salmon), and have a much stronger salmon flavor than farm raised salmon. \n",
      "\n",
      "\n",
      "\n",
      "Predicted Answer: ['Baking soda is pure sodium bicarbonate, while baking powder includes an acidifying agent (cream of tartar) and a drying agent (starch).\\n\\n\\nYou can substitute baking soda for baking powder if you already have an acidifying agent in a recipe (like buttermilk).\\n\\n\\n<http://chemistry.about.com/cs/foodchemistry/f/blbaking.htm>\\n\\n\\n', 'I place the bacon in a cold oven and then turn the oven on to 400F. It takes about 15-20 minutes to get slightly crisp bacon. \\n\\n\\n', 'Normal double-acting baking powder makes CO2 (thus giving a rising effect) in two ways: when it gets wet, and when it is heated.\\n\\n\\nBaking soda only makes CO2 when it gets wet.\\n\\n\\n[From Wikipedia](http://en.wikipedia.org/wiki/Baking_powder):\\n\\n\\n\\n> \\n> The acid in a baking powder can be\\n>  either fast-acting or slow-acting.[6]\\n>  A fast-acting acid reacts in a wet\\n>  mixture with baking soda at room\\n>  temperature, and a slow-acting acid\\n>  will not react until heated in an\\n>  oven. Baking powders that contain both\\n>  fast- and slow-acting acids are double\\n>  acting; those that contain only one\\n>  acid are single acting. By providing a\\n>  second rise in the oven, double-acting\\n>  baking powders increase the\\n>  reliability of baked goods by\\n>  rendering the time elapsed between\\n>  mixing and baking less critical, and\\n>  this is the type most widely available\\n>  to consumers today. \\n> \\n> \\n> \\n\\n\\n']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Select 3 pairs from the validation set, and run your model on those 3 examples. This time, you will retrieve from all answers (answers.csv). Then, paste the question title, body, true answer and the predicted answer in the text boxes below, using the following format:\n",
    "\n",
    "Question Title: <write your question title here>\n",
    "Question Body: <write your question body here>\n",
    "True Answer: <the answer associated in the validation.csv>\n",
    "Predicted Answer: <what was retrieved by your model>\n",
    "\"\"\"\n",
    "# Select 3 pairs from the validation set\n",
    "q_titles = qa_data['valid'].loc[0 : 2, 'QuestionTitle'].tolist()\n",
    "q_bodies = qa_data['valid'].loc[0 : 2, 'QuestionBody'].tolist()\n",
    "answers = qa_data['valid'].loc[0 : 2, 'Answer'].tolist()\n",
    "# Tokenize batch and get class output\n",
    "q_batch, a_batch = tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers)\n",
    "q_batch = q_batch.to(device)\n",
    "a_batch = a_batch.to(device)\n",
    "\n",
    "q_out = get_class_output(q_enc, q_batch)\n",
    "a_out = get_class_output(a_enc, a_batch)\n",
    "\n",
    "# Get top-k indices\n",
    "indices, scores = get_topk_indices(q_out, a_out, k=10)\n",
    "indices = indices.cpu().tolist()\n",
    "# Select by indices\n",
    "selected = select_by_indices(indices, qa_data['answers']['Answer'].tolist())\n",
    "\n",
    "# print results\n",
    "for i, (title, body, true_answer, predicted_answers) in enumerate(zip(q_titles, q_bodies, answers, selected)):\n",
    "    print(f\"Question Title: {title}\")\n",
    "    print(f\"Question Body: {body}\")\n",
    "    print(f\"True Answer: {true_answer}\")\n",
    "    print(f\"Predicted Answer: {predicted_answers}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
